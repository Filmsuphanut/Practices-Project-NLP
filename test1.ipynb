{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "#import attacut\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from pythainlp import sent_tokenize, word_tokenize\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\ardwarong\\\\d1.txt',\n",
       " 'data\\\\ardwarong\\\\d10.txt',\n",
       " 'data\\\\ardwarong\\\\d2.txt',\n",
       " 'data\\\\ardwarong\\\\d3.txt',\n",
       " 'data\\\\ardwarong\\\\d4.txt',\n",
       " 'data\\\\ardwarong\\\\d5.txt',\n",
       " 'data\\\\ardwarong\\\\d6.txt',\n",
       " 'data\\\\ardwarong\\\\d7.txt',\n",
       " 'data\\\\ardwarong\\\\d8.txt',\n",
       " 'data\\\\ardwarong\\\\d9.txt']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = []\n",
    "regexp = re.compile(r'[()%*,-\\d\\s\\t\\n\"\"''‘’“”.]', re.UNICODE)\n",
    "files = glob.glob(\"data/*/**.txt\",recursive=True)\n",
    "for f in files:\n",
    "    file = open(f,mode=\"r\",encoding=\"utf-8\")\n",
    "    data = file.read()\n",
    "    data = regexp.sub('', data)\n",
    "    docs.append(data)\n",
    "    file.close()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notebook.output.textLineLimit\n",
    "doc_token = []\n",
    "for d in docs:\n",
    "   #doc_token.append(word_tokenize(d, engine=\"attacut\"))#, keep_whitespace=False))\n",
    "   doc_token.append(word_tokenize(d, engine=\"deepcut\"))#, keep_whitespace=False))\n",
    "#doc_token[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>?</th>\n",
       "      <th>Attachment</th>\n",
       "      <th>Attraction</th>\n",
       "      <th>AuthorityBias</th>\n",
       "      <th>Availability</th>\n",
       "      <th>BackfireEffect</th>\n",
       "      <th>Bang</th>\n",
       "      <th>Belief</th>\n",
       "      <th>Bias</th>\n",
       "      <th>...</th>\n",
       "      <th>ไร้</th>\n",
       "      <th>ไว</th>\n",
       "      <th>ไว้</th>\n",
       "      <th>ไหน</th>\n",
       "      <th>ไหม</th>\n",
       "      <th>ไหล</th>\n",
       "      <th>ไอน์สไตน์</th>\n",
       "      <th>ไอเดีย</th>\n",
       "      <th>ๆ</th>\n",
       "      <th>–</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037499</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024105</td>\n",
       "      <td>0.056248</td>\n",
       "      <td>0.028355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.019607</td>\n",
       "      <td>0.019607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036246</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103584</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066467</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137899</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>0.076444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>0.012637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183708</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060879</td>\n",
       "      <td>0.022508</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095237</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016072</td>\n",
       "      <td>0.021735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.025587</td>\n",
       "      <td>0.041546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038696</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071534</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1071 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          !         ?  Attachment  Attraction  AuthorityBias  Availability  \\\n",
       "0  0.037499  0.015222    0.000000    0.000000       0.000000      0.000000   \n",
       "1  0.025930  0.010526    0.019607    0.019607       0.000000      0.000000   \n",
       "2  0.037051  0.000000    0.000000    0.000000       0.000000      0.000000   \n",
       "3  0.000000  0.000000    0.000000    0.000000       0.000000      0.000000   \n",
       "4  0.000000  0.000000    0.000000    0.000000       0.000000      0.000000   \n",
       "5  0.000000  0.000000    0.000000    0.000000       0.019111      0.019111   \n",
       "6  0.000000  0.065363    0.000000    0.000000       0.000000      0.000000   \n",
       "7  0.000000  0.034571    0.000000    0.000000       0.000000      0.000000   \n",
       "8  0.000000  0.011668    0.000000    0.000000       0.000000      0.000000   \n",
       "9  0.025587  0.041546    0.000000    0.000000       0.000000      0.000000   \n",
       "\n",
       "   BackfireEffect      Bang    Belief      Bias  ...       ไร้        ไว  \\\n",
       "0        0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "1        0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.019607   \n",
       "2        0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "3        0.000000  0.000000  0.000000  0.000000  ...  0.025471  0.000000   \n",
       "4        0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "5        0.019111  0.000000  0.019111  0.076444  ...  0.000000  0.000000   \n",
       "6        0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "7        0.000000  0.032199  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "8        0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "9        0.000000  0.000000  0.000000  0.000000  ...  0.032895  0.000000   \n",
       "\n",
       "        ไว้       ไหน       ไหม       ไหล  ไอน์สไตน์    ไอเดีย         ๆ  \\\n",
       "0  0.024105  0.056248  0.028355  0.000000   0.000000  0.000000  0.073385   \n",
       "1  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.036246   \n",
       "2  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.103584   \n",
       "3  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.066467   \n",
       "4  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.137899   \n",
       "5  0.016246  0.012637  0.000000  0.000000   0.000000  0.000000  0.183708   \n",
       "6  0.000000  0.000000  0.000000  0.000000   0.000000  0.060879  0.022508   \n",
       "7  0.000000  0.021291  0.000000  0.000000   0.027372  0.000000  0.095237   \n",
       "8  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000  0.016072   \n",
       "9  0.000000  0.051174  0.000000  0.038696   0.032895  0.000000  0.071534   \n",
       "\n",
       "          –  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5  0.000000  \n",
       "6  0.000000  \n",
       "7  0.000000  \n",
       "8  0.021735  \n",
       "9  0.000000  \n",
       "\n",
       "[10 rows x 1071 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identity_fun(text):\n",
    "    return text\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer = 'word', #this is default\n",
    "                                   tokenizer=identity_fun, #does no extra tokenizing\n",
    "                                   preprocessor=identity_fun, #no extra preprocessor\n",
    "                                   token_pattern=None)\n",
    "\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(doc_token)\n",
    "tfidf_array = np.array(tfidf_vector.todense())\n",
    "#tfidf_vectorizer.vocabulary_ #ดูคำ\n",
    "\n",
    "#แปลงเป็น DataFrame เพื่อง่ายแก่การอ่าน\n",
    "df = pd.DataFrame(tfidf_array,columns=tfidf_vectorizer.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['อนันต์', 'ขนาด', 'ที่', 'ว่า', 'เซ็ต', 'จะ', 'ไม่', 'จำนวน', 'ก็', 'ถึง', 'ถ้า', 'ไป', 'อาจ', 'เร็ว', 'มี'])\n",
      " list(['สมอง', 'ที่', 'รัก', 'ความ', 'ได้', 'ส่วน', 'ใน', 'เป็น', 'การ', 'กัน', 'รู้สึก', 'จะ', 'ไป', 'พฤติกรรม', 'หน้า'])\n",
      " list(['ผลึก', 'เวลา', 'ที่', 'ห้อง', 'เป็น', 'อุณหภูมิ', 'วิจัย', 'มา', 'ระบบ', 'ใน', 'โลก', 'ควอน', 'ตัม', 'สู่', 'ได้'])\n",
      " list(['อากาศ', 'ที่', 'วัตถุ', 'เร็ว', 'ต้าน', 'แรงต้าน', 'เคลื่อน', 'แรง', 'จะ', 'ไม่', 'การ', 'ความ', 'ตัด', 'ทิ้ง', 'มาก'])\n",
      " list(['ร่างกาย', 'ทดสอบ', 'ไขมัน', 'สมอง', 'ภาวะ', 'การ', 'ใน', 'วิจัย', 'อ้วน', 'ว่า', 'ๆ', 'ลง', 'ความ', 'และ', 'คิด'])\n",
      " list(['เชื่อ', 'สมชาย', 'ที่', 'ว่า', 'คน', 'ๆ', 'ดี', 'รู้สึก', 'ไม่', 'เช่น', 'การ', 'จะ', 'ความ', 'ก็', 'เอง'])\n",
      " list(['อนุภาค', 'ได้', 'ผลิต', 'อย่าง', 'ใน', 'เหมือน', 'ที่', 'ระดับ', 'วัตถุ', 'ให้', 'สามารถ', 'หรือ', 'ไม่', 'กายภาพ', 'จับต้อง'])\n",
      " list(['เอกภพ', 'จุด', 'ที่', 'มา', 'ของ', 'ก่อนหน้า', 'บิ๊ก', 'แบง', 'ใน', 'ฟิสิกส์', 'รังสี', 'หลุม', 'มี', 'ว่า', 'เกิด'])\n",
      " list(['พันธุ์', 'กระจู๋', 'มี', 'ที่', 'ผสม', 'สืบ', 'จะ', 'ใน', 'สัตว์', 'การ', 'วิวัฒนาการ', 'อสุจิ', 'อวัยวะ', 'กระดูก', 'และ'])\n",
      " list(['หลุม', 'ดำ', 'ที่', 'โดดเดี่ยว', 'ค้น', 'มี', 'ดาราศาสตร์', 'พบ', 'มัน', 'วัตถุ', 'ว่า', 'อยู่', 'มา', 'ไม่', 'เชื่อ'])]\n"
     ]
    }
   ],
   "source": [
    "print(df.apply(lambda s: s.nlargest(15).index.tolist(), axis=1).ravel()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69eb92836b941e979072a76c7fcfffe5419cca933cedd02cfafbdfca1a93358c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
